{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6089d3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a15970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "weekly_data = pd.read_csv(r'C:\\Users\\joshu\\OneDrive\\Desktop\\CS74\\Final_Project\\music_econ_merged.csv')\n",
    "\n",
    "\n",
    "# Prepare features\n",
    "\n",
    "audio_features = ['danceability', 'energy', 'valence', 'tempo',  'acousticness', 'instrumentalness', 'speechiness',  'loudness', 'pos', 'neg']\n",
    "\n",
    "# Economic features (if you want to include them)\n",
    "econ_features = ['UNRATE', 'CPIAUCSL']\n",
    "\n",
    "# Topic features (columns '0' through '29')\n",
    "topic_features = [str(i) for i in range(30)]\n",
    "\n",
    "\n",
    "\n",
    "X = weekly_data[['danceability', 'energy', 'valence', 'tempo', \n",
    "                 'acousticness', 'instrumentalness', 'speechiness', \n",
    "                 'loudness', 'pos', 'neg']]\n",
    "\n",
    "y = weekly_data['USREC']\n",
    "\n",
    "print(f\"\\nTotal data: {len(X)} observations\")\n",
    "print(f\"Total recessions: {y.sum()} ({y.mean()*100:.1f}%)\")\n",
    "print(f\"Total normal periods: {(y==0).sum()} ({(y==0).mean()*100:.1f}%)\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2,       random_state=42,      stratify=y           \n",
    ")\n",
    "\n",
    "print(f\"Total: {len(X_train)} observations\")\n",
    "print(f\"Recessions: {y_train.sum()} ({y_train.mean()*100:.1f}%)\")\n",
    "print(f\"Normal: {(y_train==0).sum()} ({(y_train==0).mean()*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n--- TEST SET ---\")\n",
    "print(f\"Total: {len(X_test)} observations\")\n",
    "print(f\"Recessions: {y_test.sum()} ({y_test.mean()*100:.1f}%)\")\n",
    "print(f\"Normal: {(y_test==0).sum()} ({(y_test==0).mean()*100:.1f}%)\")\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    class_weight='balanced',  # Handles class imbalance\n",
    "    max_iter=1000,           # Enough iterations to converge\n",
    "    random_state=42\n",
    ")\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "baseline_accuracy = (y_test == 0).mean()  # Always predicting \"no recession\"\n",
    "\n",
    "\n",
    "print(f\"\\nðŸ”¹ Baseline (always predict no recession): {baseline_accuracy:.3f}\")\n",
    "print(f\"ðŸ”¹ Logistic Regression Accuracy:          {accuracy:.3f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nTrue Negatives (correctly predicted normal): {tn}\")\n",
    "print(f\"False Positives (predicted recession but normal): {fp}\")\n",
    "print(f\"False Negatives (missed recession): {fn}\")\n",
    "print(f\"True Positives (correctly predicted recession): {tp}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "\n",
    "\n",
    "coeff_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': log_reg.coef_[0]\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "\n",
    "print(coeff_df.to_string(index=False))\n",
    "\n",
    "top_pos = coeff_df.head(3)['Feature'].tolist()\n",
    "top_neg = coeff_df.tail(3)['Feature'].tolist()\n",
    "\n",
    "print(\"\\nMost positive predictors of recession:\", \", \".join(top_pos))\n",
    "print(\"Most negative predictors of recession:\", \", \".join(top_neg))\n",
    "\n",
    "print(\"\\nâœ… Done! Model training and evaluation complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfcfc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix\n",
    "class_names=['No Recession', 'Recession']\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e3a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# my labes for interpretation\n",
    "topic_labels = {\n",
    "    '0': \"Spiritual\", '1': \"Relationship\", '2': \"Longing\",\n",
    "    '3': \"Clarity\", '4': \"Everyday Joy\", '5': \"Dance/Party\",\n",
    "    '6': \"Heartbreak\", '7': \"Intimacy\", '8': \"Self/Body\",\n",
    "    '9': \"Party/Club\", '10': \"Bop/Dance\", '11': \"Social Talk\",\n",
    "    '12': \"Girl & Fun\", '13': \"Music & Friends\", '14': \"Time & Change\",\n",
    "    '15': \"Appreciation\", '16': \"Admiring\", '17': \"Regret\",\n",
    "    '18': \"Past/Memory\", '19': \"Hopes & Dreams\", '20': \"True Love\",\n",
    "    '21': \"Money/Power\", '22': \"Romantic\", '23': \"Hip-Hop\",\n",
    "    '24': \"Home\", '25': \"Dance & Music\", '26': \"Playfulness\",\n",
    "    '27': \"Feeling Good\", '28': \"Freaky-Deaky\", '29': \"Yearning\"\n",
    "}\n",
    "\n",
    "# Create coefficient dataframe\n",
    "coeff_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': log_reg.coef_[0]\n",
    "})\n",
    "\n",
    "# Add labels and category\n",
    "coeff_df['Label'] = coeff_df['Feature'].map(topic_labels).fillna('')  # â† FIXED: Use empty string instead of NaN\n",
    "coeff_df['Category'] = coeff_df['Feature'].apply(\n",
    "    lambda x: 'Topic' if x in topic_labels \n",
    "    else 'Economic' if x in econ_features \n",
    "    else 'Audio/Sentiment'\n",
    ")\n",
    "\n",
    "# Sort by absolute coefficient\n",
    "coeff_df['Abs_Coef'] = coeff_df['Coefficient'].abs()\n",
    "coeff_df = coeff_df.sort_values('Abs_Coef', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features:\")\n",
    "for i, row in coeff_df.head(20).iterrows():\n",
    "    feature = row['Feature']\n",
    "    coef = row['Coefficient']\n",
    "    category = row['Category']\n",
    "    label = row['Label']\n",
    "    \n",
    "    if label:  # â† FIXED: Now label is empty string instead of NaN\n",
    "        print(f\"  {feature:15s} [{category:15s}] ({label:20s}): {coef:+.4f}\")\n",
    "    else:\n",
    "        print(f\"  {feature:15s} [{category:15s}]: {coef:+.4f}\")\n",
    "\n",
    "# Separate analysis by category\n",
    "\n",
    "\n",
    "for category in ['Audio/Sentiment', 'Economic', 'Topic']:\n",
    "    cat_df = coeff_df[coeff_df['Category'] == category].head(5)\n",
    "    \n",
    "    if len(cat_df) > 0:\n",
    "        print(f\"\\n{category}:\")\n",
    "        for i, row in cat_df.iterrows():\n",
    "            feature = row['Feature']\n",
    "            coef = row['Coefficient']\n",
    "            label = row['Label']\n",
    "            label_str = f\" ({label})\" if label else \"\"  \n",
    "            print(f\"  {feature:15s}{label_str:22s}: {coef:+.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "top_recession_predictors = coeff_df.nlargest(5, 'Coefficient')\n",
    "top_normal_predictors = coeff_df.nsmallest(5, 'Coefficient')\n",
    "\n",
    "print(\"\\nTop 5 Predictors of RECESSION (+):\")\n",
    "for i, row in top_recession_predictors.iterrows():\n",
    "    label = row['Label']\n",
    "    label_str = f\" ({label})\" if label else \"\" \n",
    "    print(f\"  {row['Feature']}{label_str}: {row['Coefficient']:+.4f}\")\n",
    "\n",
    "print(\"\\nTop 5 Predictors of NORMAL (-):\")\n",
    "for i, row in top_normal_predictors.iterrows():\n",
    "    label = row['Label']\n",
    "    label_str = f\" ({label})\" if label else \"\" \n",
    "    print(f\"  {row['Feature']}{label_str}: {row['Coefficient']:+.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nPrevious (Audio + Econ only):\")\n",
    "print(\"  Recall: 86.7%\")\n",
    "print(\"  Precision: 31.7%\")\n",
    "print(\"  False Positives: 28\")\n",
    "\n",
    "print(f\"\\nCurrent (Audio + Econ + Topics):\")\n",
    "print(f\"  Recall: {recall*100:.1f}%\")\n",
    "print(f\"  Precision: {precision*100:.1f}%\")\n",
    "print(f\"  False Positives: {fp}\")\n",
    "\n",
    "# Calculate improvement\n",
    "recall_change = (recall - 0.867) * 100\n",
    "precision_change = (precision - 0.317) * 100\n",
    "fp_change = fp - 28\n",
    "\n",
    "print(f\"\\nChanges:\")\n",
    "print(f\"  Recall: {recall_change:+.1f} percentage points\")\n",
    "print(f\"  Precision: {precision_change:+.1f} percentage points\")\n",
    "print(f\"  False Positives: {fp_change:+d}\")\n",
    "\n",
    "if recall >= 0.867:\n",
    "    print(\"\\nâœ… Topics IMPROVED recall!\")\n",
    "elif recall >= 0.85:\n",
    "    print(\"\\nâš ï¸  Topics maintained similar recall\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Topics decreased recall (possible overfitting)\")\n",
    "\n",
    "if precision > 0.317:\n",
    "    print(\"âœ… Topics IMPROVED precision (fewer false alarms)!\")\n",
    "\n",
    "print(\"\\nâœ… Done! Model with topics training and evaluation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f466e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\joshu\\OneDrive\\Desktop\\CS74\\Final_Project\\music_econ_topics_merged.csv')\n",
    "\n",
    "# Define feature sets\n",
    "audio_features = ['danceability', 'energy', 'valence', 'tempo', \n",
    "                  'acousticness', 'instrumentalness', 'speechiness', \n",
    "                  'loudness', 'pos', 'neg']\n",
    "\n",
    "econ_features = ['UNRATE', 'CPIAUCSL']\n",
    "topic_features = [str(i) for i in range(30)]\n",
    "\n",
    "\n",
    "models_to_test = {\n",
    "    '1. Music Only (MAIN)': audio_features,\n",
    "    '2. Music + Economics': audio_features + econ_features,\n",
    "    '3. Music + Topics': audio_features + topic_features,\n",
    "    '4. Music + Economics + Topics (FULL)': audio_features + econ_features + topic_features\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, features in models_to_test.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{model_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Check available features\n",
    "    available = [f for f in features if f in df.columns]\n",
    "    \n",
    "    if len(available) == 0:\n",
    "        print(\"âš ï¸  No features available, skipping\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Features: {len(available)}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    df_clean = df[available + ['USREC']].dropna()\n",
    "    X = df_clean[available]\n",
    "    y = df_clean['USREC']\n",
    "    \n",
    "    print(f\"Observations: {len(X)}\")\n",
    "    \n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    model = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    # Store\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Features': len(available),\n",
    "        'Accuracy': accuracy,\n",
    "        'Recall': recall,\n",
    "        'Precision': precision,\n",
    "        'False Positives': fp,\n",
    "        'True Positives': tp,\n",
    "        'Total Recessions': tp + fn\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nRecall: {recall:.1%} ({tp}/{tp+fn} recessions caught)\")\n",
    "    print(f\"Precision: {precision:.1%}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df[['Model', 'Features', 'Recall', 'Precision', 'False Positives']]\n",
    "\n",
    "# Format as percentages\n",
    "results_df['Recall'] = results_df['Recall'].apply(lambda x: f\"{x:.1%}\")\n",
    "results_df['Precision'] = results_df['Precision'].apply(lambda x: f\"{x:.1%}\")\n",
    "\n",
    "print(\"\\n\" + results_df.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "models = ['Music\\nOnly', 'Music +\\nEconomics', 'Music +\\nTopics', 'Full\\nModel']\n",
    "recall = [86.7, 86.7, 86.7, 86.7]\n",
    "precision = [30.2, 31.7, 31.0, 32.5]\n",
    "features = [10, 12, 40, 42]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, recall, width, label='Recall', color='steelblue', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, precision, width, label='Precision', color='coral', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Model', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Percentage (%)', fontweight='bold', fontsize=12)\n",
    "ax.set_title('Model Performance: Recall vs Precision', fontweight='bold', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "ax.set_ylim([0, 100])\n",
    "ax.axhline(y=86.7, color='steelblue', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add feature count labels\n",
    "for i, (model, feat) in enumerate(zip(models, features)):\n",
    "    ax.text(i, 5, f'{feat} features', ha='center', fontsize=9, style='italic')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(r'C:\\Users\\joshu\\OneDrive\\Desktop\\CS74\\Final_Project\\model_comparison_final.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "print(\"âœ“ Saved chart\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c732285e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
