{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee651d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "K-MEANS CLUSTERING: needs improvemnt\n",
    "problems include:\n",
    "1. Only 2 clusters (K=2) - too simplistic\n",
    "2. No connection to recession periods\n",
    "5. Weak silhouette scores (0.35)\n",
    "\n",
    "SOLUTIONS:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('music_econ_topics_merged.csv')\n",
    "\n",
    "feature_cols = ['danceability', 'energy', 'valence', 'tempo', \n",
    "                'acousticness', 'instrumentalness', 'speechiness', 'loudness']\n",
    "\n",
    "df_clean = df[feature_cols + ['week_date', 'USREC']].dropna()\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_clean[feature_cols])\n",
    "\n",
    "\n",
    "# Test multiple metrics\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "calinski_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, labels))\n",
    "    calinski_scores.append(calinski_harabasz_score(X_scaled, labels))\n",
    "    \n",
    "    print(f\"K={k}: Silhouette={silhouette_scores[-1]:.3f}, Calinski-Harabasz={calinski_scores[-1]:.1f}\")\n",
    "\n",
    "# USE K=3 OR K=4 (MORE INTERPRETABLE)\n",
    "\n",
    "OPTIMAL_K = 3  \n",
    "\n",
    "kmeans_final = KMeans(n_clusters=OPTIMAL_K, random_state=42, n_init=20)\n",
    "df_clean['cluster'] = kmeans_final.fit_predict(X_scaled)\n",
    "\n",
    "print(f\"\\n‚úì Final model: K={OPTIMAL_K}\")\n",
    "print(f\"‚úì Silhouette score: {silhouette_score(X_scaled, df_clean['cluster']):.3f}\")\n",
    "\n",
    "#CREATE MEANINGFUL CLUSTER LABELS\n",
    "\n",
    "cluster_profiles = df_clean.groupby('cluster')[feature_cols].mean()\n",
    "\n",
    "def create_meaningful_labels(cluster_profiles):\n",
    "    \"\"\"\n",
    "    Create interpretable labels based on MULTIPLE features\n",
    "    \"\"\"\n",
    "    labels = {}\n",
    "    \n",
    "    for cluster in range(OPTIMAL_K):\n",
    "        profile = cluster_profiles.loc[cluster]\n",
    "        mean = cluster_profiles.mean()\n",
    "        \n",
    "        # Identify key characteristics (z-score > 0.5)\n",
    "        characteristics = []\n",
    "        \n",
    "        # Energy/Tempo\n",
    "        if profile['energy'] > mean['energy'] + 0.1 and profile['tempo'] > mean['tempo'] + 5:\n",
    "            characteristics.append(\"High-Energy/Fast\")\n",
    "        elif profile['energy'] < mean['energy'] - 0.1:\n",
    "            characteristics.append(\"Low-Energy\")\n",
    "            \n",
    "        # Acousticness\n",
    "        if profile['acousticness'] > mean['acousticness'] + 0.1:\n",
    "            characteristics.append(\"Acoustic\")\n",
    "        elif profile['acousticness'] < mean['acousticness'] - 0.05:\n",
    "            characteristics.append(\"Electric\")\n",
    "            \n",
    "        # Danceability\n",
    "        if profile['danceability'] > mean['danceability'] + 0.05:\n",
    "            characteristics.append(\"Danceable\")\n",
    "        elif profile['danceability'] < mean['danceability'] - 0.05:\n",
    "            characteristics.append(\"Non-Danceable\")\n",
    "            \n",
    "        # Valence\n",
    "        if profile['valence'] > mean['valence'] + 0.05:\n",
    "            characteristics.append(\"Positive\")\n",
    "        elif profile['valence'] < mean['valence'] - 0.05:\n",
    "            characteristics.append(\"Melancholic\")\n",
    "        \n",
    "        # Create label\n",
    "        if len(characteristics) == 0:\n",
    "            labels[cluster] = \"Balanced/Moderate\"\n",
    "        else:\n",
    "            labels[cluster] = \" / \".join(characteristics[:2])  # Top 2 characteristics\n",
    "    \n",
    "    return labels\n",
    "\n",
    "cluster_labels = create_meaningful_labels(cluster_profiles)\n",
    "\n",
    "\n",
    "\n",
    "for cluster in range(OPTIMAL_K):\n",
    "    count = (df_clean['cluster'] == cluster).sum()\n",
    "    pct = count / len(df_clean) * 100\n",
    "    print(f\"Cluster {cluster}: {cluster_labels[cluster]:<30} ({count} months, {pct:.1f}%)\")\n",
    "\n",
    "# found these to be best labels\n",
    "cluster_labels = {\n",
    "    0: \"Balanced/Mid-Energy\",\n",
    "    1: \"High-Energy/Dance\", \n",
    "    2: \"Acoustic/Positive\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for cluster in range(OPTIMAL_K):\n",
    "    recession_mask = (df_clean['cluster'] == cluster) & (df_clean['USREC'] == 1)\n",
    "    normal_mask = (df_clean['cluster'] == cluster) & (df_clean['USREC'] == 0)\n",
    "    \n",
    "    recession_count = recession_mask.sum()\n",
    "    normal_count = normal_mask.sum()\n",
    "    \n",
    "    total_recessions = (df_clean['USREC'] == 1).sum()\n",
    "    total_normal = (df_clean['USREC'] == 0).sum()\n",
    "    \n",
    "    recession_pct = (recession_count / total_recessions) * 100 if total_recessions > 0 else 0\n",
    "    normal_pct = (normal_count / total_normal) * 100 if total_normal > 0 else 0\n",
    "    \n",
    "    diff = recession_pct - normal_pct\n",
    "    \n",
    "    print(f\"\\nCluster {cluster}: {cluster_labels[cluster]}\")\n",
    "    print(f\"  Recession periods: {recession_count:2d} ({recession_pct:5.1f}% of all recession months)\")\n",
    "    print(f\"  Normal periods:    {normal_count:3d} ({normal_pct:5.1f}% of all normal months)\")\n",
    "    print(f\"  Difference:        {diff:+5.1f} percentage points\", end=\"\")\n",
    "    \n",
    "    if abs(diff) > 5:\n",
    "        if diff > 0:\n",
    "            print(\" ‚¨ÜÔ∏è MORE COMMON IN RECESSIONS\")\n",
    "        else:\n",
    "            print(\" ‚¨áÔ∏è MORE COMMON IN NORMAL TIMES\")\n",
    "    else:\n",
    "        print(\" ‚Üí SIMILAR\")\n",
    "\n",
    "# STATISTICAL TEST\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# make contingency table\n",
    "contingency_table = pd.crosstab(df_clean['cluster'], df_clean['USREC'])\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "\n",
    "print(f\"Chi-square statistic: œá¬≤ = {chi2:.4f}\")\n",
    "print(f\"P-value: p = {p_value:.6f}\")\n",
    "print(f\"Degrees of freedom: df = {dof}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"‚úÖ SIGNIFICANT: Cluster distribution differs between recession/normal periods\")\n",
    "else:\n",
    "    print(\"‚ùå NOT SIGNIFICANT: No strong evidence clusters relate to recessions\")\n",
    "\n",
    "# visuals for poster\n",
    "\n",
    "# 1. Heatmap of cluster characteristics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "ax = axes[0, 0]\n",
    "sns.heatmap(cluster_profiles.T, annot=True, fmt='.3f', cmap='RdYlGn',\n",
    "            ax=ax, cbar_kws={'label': 'Feature Value'})\n",
    "ax.set_title('Cluster Profiles: Audio Features', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Cluster')\n",
    "ax.set_ylabel('Audio Feature')\n",
    "ax.set_xticklabels([cluster_labels[i] for i in range(OPTIMAL_K)], rotation=45, ha='right')\n",
    "\n",
    "ax = axes[0, 1]\n",
    "\n",
    "recession_dist = []\n",
    "normal_dist = []\n",
    "\n",
    "for cluster in range(OPTIMAL_K):\n",
    "    # Count how many months in this cluster are recession vs normal\n",
    "    recession_count = ((df_clean['cluster'] == cluster) & (df_clean['USREC'] == 1)).sum()\n",
    "    normal_count = ((df_clean['cluster'] == cluster) & (df_clean['USREC'] == 0)).sum()\n",
    "    \n",
    "    recession_dist.append(recession_count)\n",
    "    normal_dist.append(normal_count)\n",
    "\n",
    "x = np.arange(OPTIMAL_K)\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, recession_dist, width, label='Recession', color='darkred', alpha=0.8)\n",
    "ax.bar(x + width/2, normal_dist, width, label='Normal', color='darkblue', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Cluster', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Number of Months', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Cluster Distribution: Recession vs Normal', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([cluster_labels[i] for i in range(OPTIMAL_K)], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Bottom-left: PCA visualization\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "ax = axes[1, 0]\n",
    "colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
    "for cluster in range(OPTIMAL_K):\n",
    "    mask = df_clean['cluster'] == cluster\n",
    "    ax.scatter(X_pca[mask, 0], X_pca[mask, 1], \n",
    "              c=colors[cluster], label=cluster_labels[cluster], alpha=0.6, s=50)\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
    "ax.set_title('K-means Clusters (PCA Projection)', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Bottom-right: Feature importance (distance from center)\n",
    "ax = axes[1, 1]\n",
    "feature_importance = np.abs(cluster_profiles - cluster_profiles.mean()).mean()\n",
    "feature_importance = feature_importance.sort_values(ascending=True)\n",
    "ax.barh(feature_importance.index, feature_importance.values, color='teal', alpha=0.7)\n",
    "ax.set_xlabel('Mean Absolute Deviation from Center')\n",
    "ax.set_title('Feature Discrimination Power', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/mnt/user-data/outputs/kmeans_comprehensive_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n‚úì Visualization saved!\")\n",
    "\n",
    "\n",
    "# Find most recession-associated cluster\n",
    "recession_pcts = []\n",
    "for cluster in range(OPTIMAL_K):\n",
    "    recession_mask = (df_clean['cluster'] == cluster) & (df_clean['USREC'] == 1)\n",
    "    recession_pcts.append((recession_mask.sum() / (df_clean['USREC'] == 1).sum()) * 100)\n",
    "\n",
    "most_recession_cluster = np.argmax(recession_pcts)\n",
    "least_recession_cluster = np.argmin(recession_pcts)\n",
    "\n",
    "print(f\"\\nüìä MOST COMMON DURING RECESSIONS:\")\n",
    "print(f\"   Cluster {most_recession_cluster}: {cluster_labels[most_recession_cluster]}\")\n",
    "print(f\"   {recession_pcts[most_recession_cluster]:.1f}% of recession months\")\n",
    "\n",
    "print(f\"\\nüìä LEAST COMMON DURING RECESSIONS:\")\n",
    "print(f\"   Cluster {least_recession_cluster}: {cluster_labels[least_recession_cluster]}\")\n",
    "print(f\"   {recession_pcts[least_recession_cluster]:.1f}% of recession months\")\n",
    "\n",
    "# Show key features of each\n",
    "print(f\"\\nüéµ RECESSION CLUSTER CHARACTERISTICS:\")\n",
    "profile = cluster_profiles.loc[most_recession_cluster]\n",
    "mean = cluster_profiles.mean()\n",
    "for feat in ['danceability', 'energy', 'acousticness', 'valence']:\n",
    "    diff = profile[feat] - mean[feat]\n",
    "    print(f\"   {feat:15s}: {profile[feat]:.3f} ({diff:+.3f} vs mean)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a4d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "K-Means Clustering: Recession vs Normal Comparison\n",
    "Produces single publication-ready bar chart for poster\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. LOAD DATA & SETUP\n",
    "\n",
    "df = pd.read_csv('music_econ_topics_merged.csv')\n",
    "\n",
    "feature_cols = ['danceability', 'energy', 'valence', 'tempo', \n",
    "                'acousticness', 'instrumentalness', 'speechiness', 'loudness']\n",
    "\n",
    "df_clean = df[feature_cols + ['week_date', 'USREC']].dropna()\n",
    "\n",
    "# 2. RUN K-MEANS CLUSTERING\n",
    "\n",
    "# Standardize features (required for K-means)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_clean[feature_cols])\n",
    "\n",
    "# Fit K-means with K=3\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=20)\n",
    "df_clean['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Assign interpretable labels based on cluster analysis\n",
    "cluster_labels = {\n",
    "    0: \"Balanced\",\n",
    "    1: \"High-Energy/Dance\",\n",
    "    2: \"Acoustic/Positive\"\n",
    "}\n",
    "\n",
    "print(f\"‚úì Clustered {len(df_clean)} months into 3 groups\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Calculate percentages for each cluster during recession vs normal times\n",
    "recession_pcts = []\n",
    "normal_pcts = []\n",
    "cluster_names = []\n",
    "\n",
    "for cluster in range(3):\n",
    "    # Count months in this cluster during recession/normal periods\n",
    "    recession_in_cluster = ((df_clean['cluster'] == cluster) & (df_clean['USREC'] == 1)).sum()\n",
    "    normal_in_cluster = ((df_clean['cluster'] == cluster) & (df_clean['USREC'] == 0)).sum()\n",
    "    \n",
    "    total_recession = (df_clean['USREC'] == 1).sum()\n",
    "    total_normal = (df_clean['USREC'] == 0).sum()\n",
    "    \n",
    "    recession_pct = (recession_in_cluster / total_recession) * 100\n",
    "    normal_pct = (normal_in_cluster / total_normal) * 100\n",
    "    \n",
    "    recession_pcts.append(recession_pct)\n",
    "    normal_pcts.append(normal_pct)\n",
    "    cluster_names.append(cluster_labels[cluster])\n",
    "\n",
    "# Create grouped bar chart\n",
    "x = np.arange(len(cluster_names))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, recession_pcts, width, label='Recession', \n",
    "               color='darkred', alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "bars2 = ax.bar(x + width/2, normal_pcts, width, label='Normal', \n",
    "               color='steelblue', alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Add percentage labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1f}%',\n",
    "                ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel('Cluster Type', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Percentage of Months (%)', fontsize=14, fontweight='bold')\n",
    "ax.set_title('K-means Clustering: Music Patterns During Recession vs Normal Times', \n",
    "             fontsize=15, fontweight='bold', pad=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(cluster_names, fontsize=12)\n",
    "ax.legend(fontsize=12, loc='upper left')\n",
    "ax.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
    "ax.set_ylim(0, 60)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('kmeans_recession_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Chart saved as 'kmeans_recession_comparison.png'\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "for i, cluster in enumerate(range(3)):\n",
    "    diff = recession_pcts[i] - normal_pcts[i]\n",
    "    print(f\"\\n{cluster_labels[cluster]:20s}:\")\n",
    "    print(f\"  Normal:    {normal_pcts[i]:5.1f}%\")\n",
    "    print(f\"  Recession: {recession_pcts[i]:5.1f}%\")\n",
    "    print(f\"  Change:    {diff:+5.1f} percentage points\", end=\"\")\n",
    "    \n",
    "    if abs(diff) > 10:\n",
    "        print(f\" {'‚Üë MAJOR SHIFT' if diff > 0 else '‚Üì MAJOR SHIFT'}\")\n",
    "    elif abs(diff) > 5:\n",
    "        print(f\" {'‚Üë' if diff > 0 else '‚Üì'}\")\n",
    "    else:\n",
    "        print(\" (minimal change)\")\n",
    "\n",
    "# Statistical test\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "contingency_table = pd.crosstab(df_clean['cluster'], df_clean['USREC'])\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f\"\\nStatistical Test: œá¬≤ = {chi2:.2f}, p = {p_value:.4f}\")\n",
    "print(f\"Result: {'‚úì Significant relationship' if p_value < 0.05 else '‚úó Not significant'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1600a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
